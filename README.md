ğŸš€ DocuMind AI
RAG-Based Intelligent Document Simplification & Chat System

Upload complex documents.
Ask questions.
Get simplified, intelligent responses powered by Retrieval-Augmented Generation (RAG).

ğŸŒŸ Overview

DocuMind AI is a production-ready, Dockerized RAG (Retrieval-Augmented Generation) system that allows users to:

ğŸ“„ Upload documents (PDF / DOCX)

ğŸ” Automatically process and chunk text

ğŸ§  Generate embeddings using OpenAI

ğŸ“š Store vectors in FAISS

ğŸ’¬ Ask contextual questions about uploaded documents

âœ¨ Receive simplified, intelligent responses

Built with a scalable microservice architecture using FastAPI + Docker + Nginx.

ğŸ—ï¸ Architecture
User
  â†“
Frontend (Nginx)
  â†“
FastAPI Backend
  â†“
Document Processing
  â†“
Chunking
  â†“
OpenAI Embeddings
  â†“
FAISS Vector Store
  â†“
RAG Response Generation
âš™ï¸ Tech Stack
ğŸ”¹ Backend

FastAPI

Uvicorn

LangChain

OpenAI API

FAISS (Vector DB)

Pydantic

Loguru (Structured Logging)

ğŸ”¹ Frontend

HTML / CSS

Nginx (Containerized static server)

ğŸ”¹ DevOps & Deployment

Docker & Docker Compose

Docker Hub

GitHub (CI/CD ready)

AWS EC2 (Deployment Ready Architecture)

ğŸ§  Key Features

âœ” Retrieval-Augmented Generation (RAG)
âœ” Vector search using FAISS
âœ” Context-aware document Q&A
âœ” Automatic chunking & embedding
âœ” Fully Dockerized
âœ” Environment-based configuration
âœ” Production-ready structure
âœ” Modular backend architecture

ğŸ“‚ Project Structure
DocuMind/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ rag/
â”‚   â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ utils/
â”‚   â””â”€â”€ app.py
â”‚
â”œâ”€â”€ frontend/
â”‚
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
ğŸ³ Docker Setup
1ï¸âƒ£ Build Image
docker build -t documind-backend .
2ï¸âƒ£ Run with Docker Compose
docker compose up --build
3ï¸âƒ£ Access Application

Frontend:

http://localhost:3000

Backend:

http://localhost:8000
ğŸ” Environment Variables

Create a .env file:

LLM_PROVIDER=openai
OPENAI_API_KEY=your_openai_key_here
ğŸ“¦ Docker Hub Image

Pull the latest production image:

docker pull aa10sh/aa10sh-documind-ai:latest
ğŸš€ Deployment Strategy

Designed for:

GitHub Actions CI/CD

Docker Hub Auto Push

AWS EC2 Deployment

Production-Grade Infrastructure

Future-ready for:

Kubernetes

ECS / Fargate

Vercel Frontend Integration

ğŸ§© How It Works (RAG Flow)

Document uploaded

Text extracted (PDF/DOCX)

Text split into semantic chunks

Embeddings generated via OpenAI

Stored in FAISS vector database

User question converted to embedding

Relevant chunks retrieved

Context injected into LLM

Intelligent answer generated



ğŸ“Œ Future Improvements

Multi-user authentication

Persistent vector storage (S3 / DB)

Streaming responses

UI enhancement

Multi-document support

Role-based access

ğŸ‘¨â€ğŸ’» Author

Adarsh Singh
Technocrat | ML & Systems Enthusiast
Building production-grade AI systems.
